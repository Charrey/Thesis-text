\chapter{Discussion}
\label{chapter:discussion}
\section{Algorithm}
We created an algorithm `toolbox' for our algorithm RTSH with many changeable settings. We benchmarked these settings against each other in the previous section an obtained informative results about their impact on performance. Firstly, we found that in-place depth first search path iteration is (of the methods compared) the most efficient path iteration method to replace Xiao's structure with precomputed paths for our business case. The memory usage of each path iteration methods is approximately polynomial and far below the memory limits of any pc of this era. All path iteration methods (except for control point iteration) seem to scale approximately equally within our graph size range with depth first search being the fastest method.

Our experiments show that the GreatestConstrainedFirst source graph vertex ordering from RI-DS \cite{RIalgorithm} is indeed more efficient than a random ordering. Moreover, the experiments show that ordering target vertices by degree introduced by Glasgow \cite{McCreesh2015} is on average more efficient than a random ordering or the distance-based ordering we introduced.

We benchmarked contraction and observed that it generally increases the performance of our algorithm. However, for smaller graph ranges there still existed a significant portion of test cases for which contraction was slightly slower. These cases are ones with subgraph homeomorphisms found so quickly that the minor additional computations introduced by contraction started to matter.

We compare each of our 24 combined pruning methods and conclude that \textit{cached AllDifferent pruning with N-filtering} is the most computationally effective pruning method for our business case. This finding is partly in line with Xiao's algorithm, which uses a very similar form of pruning, but with ZeroDomain pruning.

With regards to space usage, we observe that the fastest pruning method (i.e. cached AllDifferent pruning with N-filtering) uses superlinearly scaling space. However, these space requirements are still far below hardware limitations for cases with challenging computational complexity. 

For applications of our algorithm outside of FPGA emulation, different settings may yield better performance. Our test cases are specifically designed to represent graphs that adhere to our FPGA graph model and may have properties that graphs from a different domain do not have. Therefore, verifying the appropriate settings for a different business case is advisable if computational requirements are relevant.

\section{Representativeness of test cases}
For our research, we aimed to have our test cases as close to real business cases, yet randomised and of any desired size to allow benchmarking of our algorithm. With this in mind, we devised a method of generating test cases with a guaranteed subgraph homeomorphism. While these test cases adhere to our graph model of FPGAs, they might not be representative of real business cases. For example:

\begin{itemize}
\item Our test cases allow two wires to be connected through multiple configurable transistors, while in practice there will likely only one.
\item Our test cases allow different logical units to have a different number of in- and outputs, while in practice these are likely equal within the same FPGA architecture.
\item Our test cases allow FPGA structures that can have no functional purpose (for example, a logical unit without outputs).
\end{itemize}

Because of these examples and many more, our benchmarks will likely differ somewhat from the average time needed to find subgraph homeomorphisms in real business cases. Our test case generation methodology can be considered a best effort to balance representativity of real FPGAs with testability while guaranteeing presence of a subgraph homeomorphism.

\section{Scalability}

The performance of our set of optimal configurations performs well enough for our FPGA business case. From the test results, we estimated to require 39 minutes of computation for our business case or cases of comparable size. Computing this once for each pair of virtual FPGA and concrete FPGA is feasible.

\section{Disadvantages}

A disadvantage of our approach is that it requires modelling the virtual FPGA into hardware components (wires, transistors et cetera). Some models might result in subgraph homeomorphisms being found, while some models might not. A possible technique to remedy this is to attempt several different models simultaneously, using heuristics to estimate the likeliness of each model to result in a subgraph homeomorphism being found.

Even then, a subgraph homeomorphism may not be found even though a theoretical emulation exists: our methodology only looks for emulation of individual virtual components by individual concrete components and does not look for solutions where sets of virtual components are emulated by sets of virtual concrete components that may be composed of different component types. However, there might not be a solution to this: in general, an emulation mapping should map each possible function on the virtual FPGA to a semantically equivalent function on the concrete FPGA. Deciding whether two functions are semantically equivalent is an undecidable problem in general, only limited by the size of the FPGA. It is thus appropriate to use a methodology that is most likely to find an emulation mapping where one exists, for which we provide a candidate with our methodology.